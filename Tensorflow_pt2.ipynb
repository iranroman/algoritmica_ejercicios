{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs in Tensorflow #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('songdata.csv')\n",
    "df['text'] = 'trats ' + df['text'] + ' dne' # start (\"trats\") and end (\"dne\") tokens\n",
    "data = df['text'].str.cat(sep=' ').lower() # lowercase all strings \n",
    "data = ' '.join(word.strip(string.punctuation) for word in data.split()) # remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a bit of the data\n",
    "from collections import Counter\n",
    "n_chars = 102\n",
    "counts = Counter(data[0:n_chars].split(' ')) # using only the first 1000 characters in the string of lyrics]\n",
    "count_pairs = sorted(counts.items(), key=lambda x: (-x[1], x[0])) # sort first by incidence, then by alpha numeric key\n",
    "words, word_count = list(zip(*count_pairs))\n",
    "word_to_id = dict(zip(words, range(len(words)))) # get an ID for each word\n",
    "id_to_word = dict(zip(range(len(words)), words)) # get a word for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_word = data[0:n_chars].split(' ') # using only the first 1000 characters in the string of lyrics\n",
    "all_data_id = [word_to_id[word] for word in all_data_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# into a sparse matrix\n",
    "V = len(word_to_id)\n",
    "N = len(all_data_id)\n",
    "x_tr = np.zeros((N,V))\n",
    "x_tr[range(N),all_data_id] = 1\n",
    "\n",
    "y_tr = np.zeros((N,V)).astype(int)\n",
    "y_tr[range(N),all_data_id] = 1\n",
    "\n",
    "# initializing NN parameters\n",
    "H = 10\n",
    "h_0 = np.zeros((1,H)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final training loss is:  2.88558\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow \n",
    "lr = 0.01\n",
    "\n",
    "X = tf.placeholder(\"float\", [N, V])\n",
    "Y = tf.placeholder(\"int32\", [N, V])\n",
    "h_zero = tf.placeholder(\"float\", [1, H])\n",
    "\n",
    "W_i = tf.Variable(np.random.rand(V, H), dtype=tf.float32)\n",
    "b_i = tf.Variable(np.zeros((1,H)), dtype=tf.float32)\n",
    "\n",
    "W_h = tf.Variable(np.random.rand(H,H), dtype=tf.float32)\n",
    "\n",
    "W_o = tf.Variable(np.random.rand(H, V),dtype=tf.float32)\n",
    "b_o = tf.Variable(np.zeros((1,V)), dtype=tf.float32)\n",
    "\n",
    "X_ts = tf.unstack(X, axis = 0)\n",
    "Y_ts = tf.unstack(Y, axis = 0)\n",
    "Y_ts = [tf.reshape(y, [1,V]) for y in Y_ts]\n",
    "\n",
    "# Forward pass\n",
    "all_h = []\n",
    "h_prev = h_zero\n",
    "for x_t in X_ts:\n",
    "    x_t = tf.reshape(x_t, [1, V])\n",
    "    h_t = tf.nn.tanh(tf.matmul(x_t,W_i) + b_i + tf.matmul(h_prev,W_h))\n",
    "\n",
    "    all_h.append(h_t)\n",
    "    h_prev = h_t\n",
    "\n",
    "all_scores = [tf.matmul(h_t, W_o) + b_o for h_t in all_h] #Broadcasted addition\n",
    "all_y_hat = [tf.nn.softmax(scores) for scores in all_scores]\n",
    "\n",
    "all_losses = [tf.nn.softmax_cross_entropy_with_logits(logits, labels) for logits, labels in zip(all_y_hat,Y_ts)]\n",
    "total_loss = tf.reduce_mean(all_losses)\n",
    "\n",
    "GD_step = tf.train.GradientDescentOptimizer(lr).minimize(total_loss)\n",
    "\n",
    "# everything we have done so far has set up the tensorflow graph, but will not make the neural\n",
    "# network learn. For learning to take place, we need to initialize a tensorflow session and initialize \n",
    "# all the variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# you can loop over this to train over more than one epoch.\n",
    "nepochs = 1\n",
    "for i in xrange(nepochs):\n",
    "    \n",
    "    # gradient descent    \n",
    "    sess.run(GD_step, feed_dict={X: x_tr, Y: y_tr, h_zero: h_0})\n",
    "\n",
    "# If you want to obtain the accuracy of the network on the training set:\n",
    "final_loss = sess.run(total_loss, feed_dict={X: x_tr, Y: y_tr, h_zero: h_0})\n",
    "print \"The final training loss is: \", final_loss\n",
    "\n",
    "sess.close()              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
